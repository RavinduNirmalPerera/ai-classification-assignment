{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# AI Assignment: Classification Models on Covertype Dataset\n", "Author: [Ravindu Perera]\n\n", "This notebook implements and evaluates Support Vector Machine (SVM), Na\u00efve Bayes (NB), and Deep Neural Network (DNN) classifiers on the Covertype dataset."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install required packages if not already installed\n", "!pip install scikit-learn pandas matplotlib seaborn imbalanced-learn tensorflow"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import matplotlib.pyplot as plt\n", "import seaborn as sns\n", "from sklearn.datasets import fetch_covtype\n", "from sklearn.model_selection import train_test_split\n", "from sklearn.preprocessing import StandardScaler\n", "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n", "from sklearn.svm import SVC\n", "from sklearn.naive_bayes import GaussianNB\n", "from sklearn.metrics import ConfusionMatrixDisplay\n", "from imblearn.over_sampling import SMOTE\n", "import tensorflow as tf\n", "from tensorflow.keras.models import Sequential\n", "from tensorflow.keras.layers import Dense\n", "from tensorflow.keras.utils import to_categorical"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Load and Preprocess Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = fetch_covtype(as_frame=True)\n", "X, y = data.data, data.target\n", "print(\"Dataset shape:\", X.shape)\n", "print(\"Number of classes:\", len(np.unique(y)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Train-test split\n", "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n", "\n", "# Apply SMOTE\n", "smote = SMOTE(random_state=42)\n", "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n", "\n", "# Normalize features\n", "scaler = StandardScaler()\n", "X_train_scaled = scaler.fit_transform(X_resampled)\n", "X_test_scaled = scaler.transform(X_test)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## SVM Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["svm = SVC(kernel='rbf')\n", "svm.fit(X_train_scaled, y_resampled)\n", "y_pred_svm = svm.predict(X_test_scaled)\n", "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n", "print(classification_report(y_test, y_pred_svm))\n", "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_svm)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Na\u00efve Bayes Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nb = GaussianNB()\n", "nb.fit(X_train_scaled, y_resampled)\n", "y_pred_nb = nb.predict(X_test_scaled)\n", "print(\"Na\u00efve Bayes Accuracy:\", accuracy_score(y_test, y_pred_nb))\n", "print(classification_report(y_test, y_pred_nb))\n", "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_nb)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Deep Neural Network (DNN)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# One-hot encode target for DNN\n", "y_train_cat = to_categorical(y_resampled - 1)\n", "y_test_cat = to_categorical(y_test - 1)\n", "\n", "# Build model\n", "model = Sequential([\n", "    Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n", "    Dense(32, activation='relu'),\n", "    Dense(7, activation='softmax')\n", "])\n", "\n", "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n", "\n", "# Train\n", "history = model.fit(X_train_scaled, y_train_cat, epochs=20, batch_size=128, validation_split=0.2, verbose=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Evaluate\n", "loss, accuracy = model.evaluate(X_test_scaled, y_test_cat)\n", "print(\"DNN Test Accuracy:\", accuracy)\n", "\n", "# Predict and show classification report\n", "y_pred_dnn = model.predict(X_test_scaled)\n", "y_pred_classes = np.argmax(y_pred_dnn, axis=1) + 1\n", "print(classification_report(y_test, y_pred_classes))\n", "ConfusionMatrixDisplay.from_predictions(y_test, y_pred_classes)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Accuracy & Loss Plots"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot training & validation accuracy/loss\n", "plt.figure(figsize=(12, 5))\n", "plt.subplot(1, 2, 1)\n", "plt.plot(history.history['accuracy'], label='Train Accuracy')\n", "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n", "plt.title('DNN Accuracy')\n", "plt.legend()\n", "\n", "plt.subplot(1, 2, 2)\n", "plt.plot(history.history['loss'], label='Train Loss')\n", "plt.plot(history.history['val_loss'], label='Val Loss')\n", "plt.title('DNN Loss')\n", "plt.legend()\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.11"}}, "nbformat": 4, "nbformat_minor": 2}